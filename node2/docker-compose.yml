services:
  ray-worker:
    image: vllm/vllm-openai:latest
    container_name: ray-worker
    hostname: ray-worker
    network_mode: host
    ipc: host
    restart: unless-stopped
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_TOKEN=${HF_TOKEN}
      - RAY_HEAD_IP=${RAY_HEAD_IP:-10.15.105.105}
      # Critical: Set the host IP for vLLM and Ray to use (this node's IP)
      - VLLM_HOST_IP=${VLLM_HOST_IP:-10.15.105.107}
      # Disable Ray metrics to avoid Ray 2.53 bug (ray-project/ray#59665)
      - RAY_DISABLE_DOCKER_CPU_WARNING=1
      - RAY_metrics_report_interval_ms=0
      # Network interface for distributed communication (GLOO/NCCL)
      - GLOO_SOCKET_IFNAME=${NETWORK_INTERFACE:-ens33}
      - NCCL_SOCKET_IFNAME=${NETWORK_INTERFACE:-ens33}
      - TP_SOCKET_IFNAME=${NETWORK_INTERFACE:-ens33}
    volumes:
      - ${MODEL_CACHE_DIR:-./models}:/root/.cache/huggingface
      - ./data:/data
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        echo "Starting Ray worker on IP: $VLLM_HOST_IP, connecting to head: $RAY_HEAD_IP"

        ray start \
          --address="${RAY_HEAD_IP}:6379" \
          --node-ip-address=$VLLM_HOST_IP \
          --num-gpus=2 \
          --block
    shm_size: 10gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
